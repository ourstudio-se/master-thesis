{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9757a887c4c4340b10b7ff3f890a09b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exjobb data prepare loading...   \n",
      "data loaded ....\n"
     ]
    }
   ],
   "source": [
    "from exjobb_data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('CarBinarizer', 'rb') as f:\n",
    "    cb = pickle.load(f)\n",
    "with open('VolvoStats', 'rb') as f:\n",
    "    stats = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import types\n",
    "import tempfile\n",
    "import keras.models\n",
    "\n",
    "def make_keras_picklable():\n",
    "    def __getstate__(self):\n",
    "        model_str = \"\"\n",
    "        with tempfile.NamedTemporaryFile(suffix='.hdf5', delete=True) as fd:\n",
    "            keras.models.save_model(self, fd.name, overwrite=True)\n",
    "            model_str = fd.read()\n",
    "        d = { 'model_str': model_str }\n",
    "        return d\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        with tempfile.NamedTemporaryFile(suffix='.hdf5', delete=True) as fd:\n",
    "            fd.write(state['model_str'])\n",
    "            fd.flush()\n",
    "            model = keras.models.load_model(fd.name)\n",
    "        self.__dict__ = model.__dict__\n",
    "\n",
    "\n",
    "    cls = keras.models.Model\n",
    "    cls.__getstate__ = __getstate__\n",
    "    cls.__setstate__ = __setstate__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using new data...\n"
     ]
    }
   ],
   "source": [
    "train,test,dev,train_ct,train_eng,train_sv,train_gb,train_col,train_uph=set_data(use_new=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antal_inpendlare</th>\n",
       "      <th>antal_utpendlare</th>\n",
       "      <th>förvärvs-arbetande</th>\n",
       "      <th>ej_förvärvs-arbetande</th>\n",
       "      <th>äganderätt/småhus</th>\n",
       "      <th>bostadsrätt</th>\n",
       "      <th>hyresrätt</th>\n",
       "      <th>övriga_inkl._uppgift_saknas</th>\n",
       "      <th>förgymnasial</th>\n",
       "      <th>gymnasial</th>\n",
       "      <th>eftergymnasial_mindre_än_3_år</th>\n",
       "      <th>eftergymnasial_3_år_eller_längre_inkl._forskarutbildning</th>\n",
       "      <th>0-6_år</th>\n",
       "      <th>7-15_år</th>\n",
       "      <th>16-19_år</th>\n",
       "      <th>20-24_år</th>\n",
       "      <th>25-44_år</th>\n",
       "      <th>45-64_år</th>\n",
       "      <th>65-w_år</th>\n",
       "      <th>låg_inkomst</th>\n",
       "      <th>medellåg_inkomst</th>\n",
       "      <th>medelhög_inkomst</th>\n",
       "      <th>hög_inkomst</th>\n",
       "      <th>medianinkomst</th>\n",
       "      <th>sammanboende_med_barn</th>\n",
       "      <th>sammanboende_utan_barn</th>\n",
       "      <th>ensamstående_med_barn</th>\n",
       "      <th>ensamstående_utan_barn</th>\n",
       "      <th>övriga_hushåll</th>\n",
       "      <th>låg_köpkraft</th>\n",
       "      <th>medellåg_köpkraft</th>\n",
       "      <th>medelhög_köpkraft</th>\n",
       "      <th>hög_köpkraft</th>\n",
       "      <th>median_köpkraft</th>\n",
       "      <th>jordbruk,_skogsbruk,_jakt_och_fiske</th>\n",
       "      <th>tillverkning_och_utvinning</th>\n",
       "      <th>energi_och_miljöverksamhet</th>\n",
       "      <th>byggverksamhet</th>\n",
       "      <th>handel</th>\n",
       "      <th>transport_och_magasinering</th>\n",
       "      <th>hotell-_och_restaurangverksamhet</th>\n",
       "      <th>information_och_kommunikation</th>\n",
       "      <th>finans-_och_försäkringsverksamhet</th>\n",
       "      <th>fastighetsverksamhet</th>\n",
       "      <th>företagstjänster</th>\n",
       "      <th>offentlig_förvaltning_och_försvar</th>\n",
       "      <th>utbildning</th>\n",
       "      <th>vård_och_omsorg,_sociala_tjänster</th>\n",
       "      <th>kulturella_och_personliga_tjänster_m.m.</th>\n",
       "      <th>okänd_verksamhet</th>\n",
       "      <th>0_barn</th>\n",
       "      <th>1_barn</th>\n",
       "      <th>2_barn</th>\n",
       "      <th>3+_barn</th>\n",
       "      <th>TYPECODE_onehot</th>\n",
       "      <th>ENGINECODE_onehot</th>\n",
       "      <th>SALESVERSIONCODE_onehot</th>\n",
       "      <th>GEARBOXCODE_onehot</th>\n",
       "      <th>COLOUR_onehot</th>\n",
       "      <th>UPHOLSTERY_onehot</th>\n",
       "      <th>OPT_CODES_onehot</th>\n",
       "      <th>TYPECODE_translated</th>\n",
       "      <th>ENGINECODE_translated</th>\n",
       "      <th>SALESVERSIONCODE_translated</th>\n",
       "      <th>GEARBOXCODE_translated</th>\n",
       "      <th>COLOUR_translated</th>\n",
       "      <th>UPHOLSTERY_translated</th>\n",
       "      <th>OPT_CODES_translated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [antal_inpendlare, antal_utpendlare, förvärvs-arbetande, ej_förvärvs-arbetande, äganderätt/småhus, bostadsrätt, hyresrätt, övriga_inkl._uppgift_saknas, förgymnasial, gymnasial, eftergymnasial_mindre_än_3_år, eftergymnasial_3_år_eller_längre_inkl._forskarutbildning, 0-6_år, 7-15_år, 16-19_år, 20-24_år, 25-44_år, 45-64_år, 65-w_år, låg_inkomst, medellåg_inkomst, medelhög_inkomst, hög_inkomst, medianinkomst, sammanboende_med_barn, sammanboende_utan_barn, ensamstående_med_barn, ensamstående_utan_barn, övriga_hushåll, låg_köpkraft, medellåg_köpkraft, medelhög_köpkraft, hög_köpkraft, median_köpkraft, jordbruk,_skogsbruk,_jakt_och_fiske, tillverkning_och_utvinning, energi_och_miljöverksamhet, byggverksamhet, handel, transport_och_magasinering, hotell-_och_restaurangverksamhet, information_och_kommunikation, finans-_och_försäkringsverksamhet, fastighetsverksamhet, företagstjänster, offentlig_förvaltning_och_försvar, utbildning, vård_och_omsorg,_sociala_tjänster, kulturella_och_personliga_tjänster_m.m., okänd_verksamhet, 0_barn, 1_barn, 2_barn, 3+_barn, TYPECODE_onehot, ENGINECODE_onehot, SALESVERSIONCODE_onehot, GEARBOXCODE_onehot, COLOUR_onehot, UPHOLSTERY_onehot, OPT_CODES_onehot, TYPECODE_translated, ENGINECODE_translated, SALESVERSIONCODE_translated, GEARBOXCODE_translated, COLOUR_translated, UPHOLSTERY_translated, OPT_CODES_translated]\n",
       "Index: []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_dict = {}\n",
    "for idx in range(len(pno12_solver.pno12s)):\n",
    "    _,ct,eng,sv,gb = re.findall(r'(..PNO12..)(...)_(..)_(..)_(.)',pno12_solver.pno12s[idx][0])[0]\n",
    "    c2i = pno12_solver.solver_data['css'][ct].c2i\n",
    "    \n",
    "    colors=list(map(lambda x: x[-5:],filter(lambda x: 'COL' in x,c2i.keys())))\n",
    "    uphs=list(map(lambda x: x[-6:],filter(lambda x: 'UPH' in x,c2i.keys())))\n",
    "    opts=list(map(lambda x: x[-6:],filter(lambda x: 'OPT' in x,c2i.keys())))\n",
    "    \n",
    "    if not ct in model_dict:\n",
    "        model_dict[ct] = {\n",
    "            'ENGINE':set([eng]),\n",
    "            'SALES_VERSION':set([sv]),\n",
    "            'GEARBOX': set([gb]),\n",
    "            'OPT':set(opts),\n",
    "            'COL':set(colors),\n",
    "            'UPH':set(uphs)\n",
    "        }\n",
    "    else:\n",
    "        model_dict[ct]['ENGINE'].add(eng)\n",
    "        model_dict[ct]['SALES_VERSION'].add(sv)\n",
    "        model_dict[ct]['GEARBOX'].add(gb)\n",
    "        model_dict[ct]['OPT'].update(opts)\n",
    "        model_dict[ct]['UPH'].update(uphs)\n",
    "        model_dict[ct]['COL'].update(colors)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "536_eng_model, computed output size: 6, specified size: 6\n",
      "536_sv_model, computed output size: 5, specified size: 5\n",
      "536_gearbox_model, computed output size: 5, specified size: 5\n",
      "536_col_model, computed output size: 13, specified size: 13\n",
      "536_uph_model, computed output size: 8, specified size: 8\n",
      "536_opt_model, computed output size: 77, specified size: 77\n",
      "234_eng_model, computed output size: 7, specified size: 7\n",
      "234_sv_model, computed output size: 3, specified size: 3\n",
      "234_gearbox_model, computed output size: 3, specified size: 3\n",
      "234_col_model, computed output size: 13, specified size: 13\n",
      "234_uph_model, computed output size: 26, specified size: 26\n",
      "234_opt_model, computed output size: 96, specified size: 96\n",
      "256_eng_model, computed output size: 4, specified size: 4\n",
      "256_sv_model, computed output size: 8, specified size: 8\n",
      "256_gearbox_model, computed output size: 1, specified size: 1\n",
      "256_col_model, computed output size: 14, specified size: 14\n",
      "256_uph_model, computed output size: 26, specified size: 26\n",
      "256_opt_model, computed output size: 91, specified size: 91\n",
      "235_eng_model, computed output size: 8, specified size: 8\n",
      "235_sv_model, computed output size: 3, specified size: 3\n",
      "235_gearbox_model, computed output size: 3, specified size: 3\n",
      "235_col_model, computed output size: 16, specified size: 16\n",
      "235_uph_model, computed output size: 26, specified size: 26\n",
      "235_opt_model, computed output size: 138, specified size: 138\n",
      "246_eng_model, computed output size: 7, specified size: 7\n",
      "246_sv_model, computed output size: 3, specified size: 3\n",
      "246_gearbox_model, computed output size: 4, specified size: 4\n",
      "246_col_model, computed output size: 15, specified size: 15\n",
      "246_uph_model, computed output size: 19, specified size: 19\n",
      "246_opt_model, computed output size: 84, specified size: 84\n",
      "236_eng_model, computed output size: 4, specified size: 4\n",
      "236_sv_model, computed output size: 1, specified size: 1\n",
      "236_gearbox_model, computed output size: 1, specified size: 1\n",
      "236_col_model, computed output size: 14, specified size: 14\n",
      "236_uph_model, computed output size: 25, specified size: 25\n",
      "236_opt_model, computed output size: 126, specified size: 126\n",
      "225_eng_model, computed output size: 6, specified size: 6\n",
      "225_sv_model, computed output size: 3, specified size: 3\n",
      "225_gearbox_model, computed output size: 3, specified size: 3\n",
      "225_col_model, computed output size: 14, specified size: 14\n",
      "225_uph_model, computed output size: 19, specified size: 19\n",
      "225_opt_model, computed output size: 97, specified size: 97\n",
      "525_eng_model, computed output size: 3, specified size: 3\n",
      "525_sv_model, computed output size: 1, specified size: 1\n",
      "525_gearbox_model, computed output size: 1, specified size: 1\n",
      "525_col_model, computed output size: 8, specified size: 8\n",
      "525_uph_model, computed output size: 1, specified size: 1\n",
      "525_opt_model, computed output size: 54, specified size: 54\n",
      "526_eng_model, computed output size: 1, specified size: 1\n",
      "526_sv_model, computed output size: 1, specified size: 1\n",
      "526_gearbox_model, computed output size: 1, specified size: 1\n",
      "526_col_model, computed output size: 14, specified size: 14\n",
      "526_uph_model, computed output size: 15, specified size: 15\n",
      "526_opt_model, computed output size: 76, specified size: 76\n",
      "227_eng_model, computed output size: 1, specified size: 1\n",
      "227_sv_model, computed output size: 1, specified size: 1\n",
      "227_gearbox_model, computed output size: 1, specified size: 1\n",
      "227_col_model, computed output size: 13, specified size: 13\n",
      "227_uph_model, computed output size: 12, specified size: 12\n",
      "227_opt_model, computed output size: 82, specified size: 82\n",
      "224_eng_model, computed output size: 1, specified size: 1\n",
      "224_sv_model, computed output size: 1, specified size: 1\n",
      "224_gearbox_model, computed output size: 1, specified size: 1\n",
      "224_col_model, computed output size: 4, specified size: 4\n",
      "224_uph_model, computed output size: 1, specified size: 1\n",
      "224_opt_model, computed output size: 52, specified size: 52\n"
     ]
    }
   ],
   "source": [
    "class BNN:\n",
    "    def __init__(self,structure,ctx_size,cb,should_build=True):\n",
    "        self.cb = cb\n",
    "        self.blue_print = structure\n",
    "        self.structures = {}\n",
    "        self.ctx_size = ctx_size\n",
    "        self.ct_encoder = LabelBinarizer()\n",
    "        self.ct_encoder.fit(list(self.blue_print.keys()))\n",
    "        self.label_encoders = {}\n",
    "        if should_build:\n",
    "            self._build_model()\n",
    "        self.scaler = MinMaxScaler()\n",
    "        self.scaler_fitted = False\n",
    "        \n",
    "    def _build_model(self):\n",
    "        ## Begin with predict ct:\n",
    "        \n",
    "        ctx_in = Input(shape=(self.ctx_size,))\n",
    "        dense = Dense(1000, activation='relu')(ctx_in)\n",
    "        dense = Dense(128, activation='relu')(dense)\n",
    "        #lenblueprint = number of car_types\n",
    "        ct_out = Dense(len(self.blue_print), activation='softmax')(dense)\n",
    "        self.ct_predictor = Model(ctx_in,ct_out,name='ct_model')\n",
    "        self.ct_predictor.compile(loss='categorical_crossentropy',optimizer=optimizers.Adam(lr=0.001),metrics=['accuracy'])\n",
    "        \n",
    "        for ct in self.blue_print.keys():\n",
    "            \n",
    "            #label_encoders\n",
    "            eng_enc = LabelBinarizer()\n",
    "            gb_enc = LabelBinarizer()\n",
    "            sv_enc = LabelBinarizer()\n",
    "            col_enc = LabelBinarizer()\n",
    "            uph_enc = LabelBinarizer()\n",
    "            opt_enc = MultiLabelBinarizer()\n",
    "            \n",
    "            engines = self.blue_print[ct]['ENGINE']\n",
    "            gearboxes = self.blue_print[ct]['GEARBOX']\n",
    "            sales_versions = self.blue_print[ct]['SALES_VERSION']\n",
    "            colors = self.blue_print[ct]['COL']\n",
    "            uphs = self.blue_print[ct]['UPH']\n",
    "            opts = self.blue_print[ct]['OPT']\n",
    "            \n",
    "            eng_enc.fit(list(engines))\n",
    "            gb_enc.fit(list(gearboxes))\n",
    "            sv_enc.fit(list(sales_versions))\n",
    "            uph_enc.fit(list(uphs))\n",
    "            col_enc.fit(list(colors))\n",
    "            opt_enc.fit([list(opts)])\n",
    "            \n",
    "            self.label_encoders[ct]={\n",
    "                'ENGINE':eng_enc,\n",
    "                'GEARBOX':gb_enc,\n",
    "                'SALES_VERSION':sv_enc,\n",
    "                'UPH': uph_enc,\n",
    "                'COL': col_enc,\n",
    "                'OPT': opt_enc\n",
    "            }\n",
    "                      \n",
    "            eng_predictor = self.create_model(ctx_in, self.get_layer_size(len(engines)), layers=[128,128], name=f'{ct}_eng_model')\n",
    "            sv_predictor = self.create_model(ctx_in,self.get_layer_size(len(sales_versions)),layers=[128,128],name=f'{ct}_sv_model')\n",
    "            eng_dependency = Input(shape=(self.get_layer_size(len(engines)),))\n",
    "            gb_predictor = self.create_model([ctx_in, eng_dependency],self.get_layer_size(len(gearboxes)), layers=[128,128],name=f'{ct}_gearbox_model')\n",
    "            col_predictor = self.create_model(ctx_in, self.get_layer_size(len(colors)), layers=[128,128], name=f'{ct}_col_model')\n",
    "            uph_predictor = self.create_model(ctx_in, self.get_layer_size(len(uphs)), layers=[128,128], name=f'{ct}_uph_model')\n",
    "            opt_predictor = self.create_model(ctx_in, self.get_layer_size(len(opts)), layers=[128,128], name=f'{ct}_opt_model', is_multilabel=True)\n",
    "            \n",
    "            self.structures[ct] = {\n",
    "                'ENGINE': eng_predictor,\n",
    "                'GEARBOX':gb_predictor,\n",
    "                'SALES_VERSION': sv_predictor,\n",
    "                'COL': col_predictor,\n",
    "                'UPH':uph_predictor,\n",
    "                'OPT':opt_predictor\n",
    "            }  \n",
    "    \n",
    "    def get_layer_size(self,layer_size):\n",
    "        return layer_size if layer_size > 2 else 1\n",
    "    \n",
    "    \n",
    "    def create_model(self,inputs,output_size,layers,name,is_multilabel=False):\n",
    "        \"\"\"\n",
    "            inputs=actual inputs, either one or a list\n",
    "            output_size=number of units in last layer\n",
    "            layers = [1,2,3,4],\n",
    "            name = model name\n",
    "        \"\"\"\n",
    "        \n",
    "        first_layer = None\n",
    "        if isinstance(inputs,list):\n",
    "            first_layer = concatenate(inputs)\n",
    "        else:\n",
    "            first_layer = Dense(128,activation='relu')(inputs)\n",
    "\n",
    "        wrapper_dense = Dense(layers[0],activation='relu')(first_layer)\n",
    "        for layer_size in layers[1:]:\n",
    "            wrapper_dense = Dense(layer_size, activation='relu')(Dropout(0.3)(wrapper_dense))\n",
    "        \n",
    "        out_layer_size = self.get_layer_size(output_size)\n",
    "        out_activation = 'softmax' if out_layer_size > 1 else 'sigmoid'\n",
    "        loss = 'categorical_crossentropy' if out_layer_size > 1 else 'binary_crossentropy'\n",
    "        print(f'{name}, computed output size: {out_layer_size}, specified size: {output_size}')\n",
    "        \n",
    "        if is_multilabel:\n",
    "            out_activation = 'sigmoid'\n",
    "            loss = 'binary_crossentropy'\n",
    "        \n",
    "        out_layer = Dense(out_layer_size, activation=out_activation,name=f'last_out_{name}')(wrapper_dense)\n",
    "        model = Model(inputs=inputs, outputs=out_layer, name=name)\n",
    "        model.compile(loss=loss, optimizer=optimizers.Adam(lr=0.001),metrics=['accuracy'])\n",
    "        #print(model.summary())\n",
    "        return model\n",
    "    \n",
    "\n",
    "    def add_training_data(self,contexts,targets):\n",
    "        \n",
    "        self.train_on = {}\n",
    "        self.validate_on=None\n",
    "        seen = []\n",
    "        result = targets.progress_apply(lambda row: (self.label_encoders[row['TYPECODE_translated']]['ENGINE'].transform([row['ENGINECODE_translated']]),\\\n",
    "                                                    self.label_encoders[row['TYPECODE_translated']]['GEARBOX'].transform([row['GEARBOXCODE_translated']]),\\\n",
    "                                                     self.label_encoders[row['TYPECODE_translated']]['SALES_VERSION'].transform([row['SALESVERSIONCODE_translated']]),\\\n",
    "                                                     self.label_encoders[row['TYPECODE_translated']]['COL'].transform([row['COLOUR_translated']]),\\\n",
    "                                                     self.label_encoders[row['TYPECODE_translated']]['UPH'].transform([row['UPHOLSTERY_translated']]),\\\n",
    "                                                     self.label_encoders[row['TYPECODE_translated']]['OPT'].transform([row['OPT_CODES_translated']])),axis=1)\n",
    "        result = list(zip(*result))\n",
    "        engs_oh = list(result[0])\n",
    "        gbs_oh = list(result[1])\n",
    "        sv_oh = list(result[2])\n",
    "        col_oh = list(result[3])\n",
    "        uph_oh = list(result[4])\n",
    "        opt_oh = list(result[5])\n",
    "        \n",
    "        \n",
    "        \n",
    "   \n",
    "        cts = targets['TYPECODE_translated']\n",
    "        for ctx, ct, eng, gb, sv,col,uph,opt in tqdm_notebook(zip(contexts.values,cts.values,engs_oh,gbs_oh,sv_oh,col_oh,uph_oh,opt_oh)):\n",
    "            if not ct in self.train_on:\n",
    "                self.train_on[ct]={\n",
    "                    'contexts':[],\n",
    "                    'ENGINE':[],\n",
    "                    'GEARBOX':[],\n",
    "                    'SALES_VERSION':[],\n",
    "                    'UPH':[],\n",
    "                    'COL':[],\n",
    "                    'OPT':[]\n",
    "                    }\n",
    "            if ct in seen:\n",
    "                continue\n",
    "\n",
    "            self.train_on[ct]['contexts']+=[ctx]\n",
    "            self.train_on[ct]['ENGINE']+=[eng[0]]\n",
    "            self.train_on[ct]['GEARBOX']+=[gb[0]]\n",
    "            self.train_on[ct]['SALES_VERSION']+=[sv[0]]\n",
    "            self.train_on[ct]['COL']+=[col[0]]\n",
    "            self.train_on[ct]['UPH']+=[uph[0]]\n",
    "            self.train_on[ct]['OPT']+=[opt[0]]         \n",
    "            \n",
    "    def add_validation_data(self,contexts,targets):\n",
    "        self.validate_on = {}\n",
    "        seen = []\n",
    "        result = targets.progress_apply(lambda row: (self.label_encoders[row['TYPECODE_translated']]['ENGINE'].transform([row['ENGINECODE_translated']]),\\\n",
    "                                                    self.label_encoders[row['TYPECODE_translated']]['GEARBOX'].transform([row['GEARBOXCODE_translated']]),\\\n",
    "                                                     self.label_encoders[row['TYPECODE_translated']]['SALES_VERSION'].transform([row['SALESVERSIONCODE_translated']]),\\\n",
    "                                                     self.label_encoders[row['TYPECODE_translated']]['COL'].transform([row['COLOUR_translated']]),\\\n",
    "                                                     self.label_encoders[row['TYPECODE_translated']]['UPH'].transform([row['UPHOLSTERY_translated']]),\\\n",
    "                                                     self.label_encoders[row['TYPECODE_translated']]['OPT'].transform([row['OPT_CODES_translated']])),axis=1)\n",
    "        result = list(zip(*result))\n",
    "        engs_oh = list(result[0])\n",
    "        gbs_oh = list(result[1])\n",
    "        sv_oh = list(result[2])\n",
    "        col_oh = list(result[3])\n",
    "        uph_oh = list(result[4])\n",
    "        opt_oh = list(result[5])\n",
    "        \n",
    "        cts = targets['TYPECODE_translated']\n",
    "        for ctx, ct, eng, gb, sv,col,uph,opt in tqdm_notebook(zip(contexts.values,cts.values,engs_oh,gbs_oh,sv_oh,col_oh,uph_oh,opt_oh)):\n",
    "            if not ct in self.validate_on:\n",
    "                self.validate_on[ct]={\n",
    "                    'contexts':[],\n",
    "                    'ENGINE':[],\n",
    "                    'GEARBOX':[],\n",
    "                    'SALES_VERSION':[],\n",
    "                    'UPH':[],\n",
    "                    'COL':[],\n",
    "                    'OPT':[]\n",
    "                    }\n",
    "            if ct in seen:\n",
    "                continue\n",
    "\n",
    "            self.validate_on[ct]['contexts']+=[ctx]\n",
    "            self.validate_on[ct]['ENGINE']+=[eng[0]]\n",
    "            self.validate_on[ct]['GEARBOX']+=[gb[0]]\n",
    "            self.validate_on[ct]['SALES_VERSION']+=[sv[0]]\n",
    "            self.validate_on[ct]['COL']+=[col[0]]\n",
    "            self.validate_on[ct]['UPH']+=[uph[0]]\n",
    "            self.validate_on[ct]['OPT']+=[opt[0]]     \n",
    "    \n",
    "    def fit(self,verbose=0,epochs=5):\n",
    "        \n",
    "        ctxs = []\n",
    "        \n",
    "        for ct in self.train_on.keys():\n",
    "            ctxs += self.train_on[ct]['contexts']\n",
    "            \n",
    "        self.scaler.fit(ctxs)\n",
    "        self.scaler_fitted = True\n",
    "        \n",
    "        t_contexts = []\n",
    "        t_cts = []\n",
    "        \n",
    "        v_contexts = []\n",
    "        v_cts = []\n",
    "        \n",
    "        def callbacks(name):\n",
    "            dt_format = \"%Y%m%d-%H%M%S\"\n",
    "            model_name = f\"{name}_{datetime.now().strftime(dt_format)}\"\n",
    "            return [\n",
    "                TensorBoard(log_dir='./logs/ksm/{}'.format(model_name)),\n",
    "                ModelCheckpoint('./models/{}.mdl_wts.hdf5'.format(model_name),\n",
    "                                save_best_only=True, monitor='val_loss', mode='min'),\n",
    "                ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n",
    "                                  patience=5, verbose=1, mode='min'),\n",
    "                EarlyStopping(restore_best_weights=True, patience=10)\n",
    "            ]\n",
    "        \n",
    "        for ct in tqdm_notebook(self.train_on.keys()):\n",
    "\n",
    "            gb_val=None\n",
    "            eng_val=None\n",
    "            sv_val = None\n",
    "            ct_val = None\n",
    "            col_val = None\n",
    "            uph_val = None\n",
    "            opt_val = None\n",
    "            \n",
    "            if (not self.validate_on is None) and (ct in self.validate_on):\n",
    "                v_ctxs = np.array(self.scaler.transform(self.validate_on[ct]['contexts']))\n",
    "                v_teng = np.array(self.validate_on[ct]['ENGINE'])\n",
    "                v_tgbs = np.array(self.validate_on[ct]['GEARBOX'])\n",
    "                v_tsv = np.array(self.validate_on[ct]['SALES_VERSION'])\n",
    "                v_tcol = np.array(self.validate_on[ct]['COL'])\n",
    "                v_tuph = np.array(self.validate_on[ct]['UPH'])\n",
    "                v_topt = np.array(self.validate_on[ct]['OPT'])\n",
    "                \n",
    "                gb_val = ([v_ctxs,v_teng],v_tgbs)\n",
    "                eng_val = (v_ctxs,v_teng)\n",
    "                sv_val = (v_ctxs, v_tsv)\n",
    "                col_val = (v_ctxs, v_tcol)\n",
    "                uph_val = (v_ctxs, v_tuph)\n",
    "                opt_val = (v_ctxs, v_topt)\n",
    "                \n",
    "                \n",
    "                v_contexts += [ctx for ctx in v_ctxs]\n",
    "                v_cts += [self.ct_encoder.transform([ct])[0] for _ in range(v_ctxs.shape[0])]\n",
    "                \n",
    "\n",
    "            encoders = self.label_encoders[ct]\n",
    "            \n",
    "            print('ct: ', ct)\n",
    "            ctxs = np.array(self.scaler.transform(self.train_on[ct]['contexts']))\n",
    "            teng = np.array(self.train_on[ct]['ENGINE'])\n",
    "            tgbs = np.array(self.train_on[ct]['GEARBOX'])\n",
    "            tsv = np.array(self.train_on[ct]['SALES_VERSION'])\n",
    "            tcol = np.array(self.train_on[ct]['COL'])\n",
    "            tuph = np.array(self.train_on[ct]['UPH'])\n",
    "            topt = np.array(self.train_on[ct]['OPT'])\n",
    "            \n",
    "            #print('fitting svs',tsv)\n",
    "            t_contexts += [ctx for ctx in ctxs]\n",
    "            t_cts += [self.ct_encoder.transform([ct])[0] for _ in range(ctxs.shape[0])]\n",
    "            #print(ctx_ct)\n",
    "            #fitting gb\n",
    "            print(f'fitting gb on {ct} with shapes ctx:{ctxs.shape}, teng:{teng.shape}, to: {tgbs.shape}')\n",
    "            self.structures[ct]['GEARBOX'].fit([ctxs,teng],tgbs,validation_data=gb_val,verbose=verbose,epochs=epochs,callbacks=callbacks('gb'))\n",
    "            #print('fitting engines',teng)\n",
    "\n",
    "            print(f'fitting eng on {ct} with shapes ctx:{ctxs.shape}, to: {teng.shape}')\n",
    "\n",
    "            self.structures[ct]['ENGINE'].fit(ctxs,teng,validation_data=eng_val,verbose=verbose,epochs=epochs,callbacks=callbacks('eng'))\n",
    "            \n",
    "            print(f'fitting sv on {ct} with shapes ctx:{ctxs.shape}, to: {tsv.shape}')\n",
    "            \n",
    "            self.structures[ct]['SALES_VERSION'].fit(ctxs,tsv,validation_data=sv_val,verbose=verbose,epochs=epochs,callbacks=callbacks('sv'))\n",
    "            \n",
    "            print(f'fitting col on {ct} with shapes ctx:{ctxs.shape}, to: {tcol.shape}')\n",
    "            \n",
    "            self.structures[ct]['COL'].fit(ctxs,tcol,validation_data=col_val,verbose=verbose,epochs=epochs,callbacks=callbacks('col'))\n",
    "            \n",
    "            print(f'fitting uph on {ct} with shapes ctx:{ctxs.shape}, to: {tuph.shape}')\n",
    "            \n",
    "            self.structures[ct]['UPH'].fit(ctxs,tuph,validation_data=uph_val,verbose=verbose,epochs=epochs,callbacks=callbacks('uph'))\n",
    "                        \n",
    "            print(f'fitting opt on {ct} with shapes ctx:{ctxs.shape}, to: {topt.shape}')\n",
    "            \n",
    "            self.structures[ct]['OPT'].fit(ctxs,topt,validation_data=opt_val,verbose=verbose,epochs=epochs,callbacks=callbacks('opt'))\n",
    "            \n",
    "            \n",
    "        print(f'fitting cartypes to contexts')\n",
    "        ct_val = None if len(v_contexts) == 0 else (np.array(v_contexts), np.array(v_cts))\n",
    "        self.ct_predictor.fit(np.array(t_contexts),np.array(t_cts),validation_data=ct_val,verbose=verbose,epochs=epochs,callbacks=callbacks('ct'))\n",
    "            \n",
    "    def predict(self,context,threshold=0.4999):\n",
    "        tctx = self.scaler.transform(context)\n",
    "        cts = self.ct_encoder.inverse_transform(self.ct_predictor.predict(tctx))\n",
    "        #print(cts)\n",
    "        def transform(encs,structure,typ,inputs,multilabel=False):\n",
    "            prediction = structure[typ].predict(inputs)\n",
    "            if multilabel:\n",
    "                oh = np.where(prediction[0] > threshold, 1, 0)\n",
    "            else:\n",
    "                oh = np.eye(prediction.shape[1])[prediction.argmax()]\n",
    "\n",
    "            inv_= encs[typ].inverse_transform(oh.reshape(1,-1))\n",
    "\n",
    "            return inv_\n",
    "\n",
    "        pcts = []\n",
    "        engs = []\n",
    "        svs = []\n",
    "        gbs = []\n",
    "        cols = []\n",
    "        uphs = []\n",
    "        opts = []\n",
    "        #print('here',tctx,cts)\n",
    "        for ctx, ct in list(zip(tctx,cts)):\n",
    "            structure = self.structures[ct]\n",
    "            enc = self.label_encoders[ct]\n",
    "            ctx_reshaped = ctx.reshape(1,-1)\n",
    "            eng = transform(enc,structure,'ENGINE',ctx_reshaped)\n",
    "            sv = transform(enc,structure,'SALES_VERSION',ctx_reshaped)\n",
    "            gb = transform(enc,structure,'GEARBOX',[ctx_reshaped,enc['ENGINE'].transform(eng)])\n",
    "            col = transform(enc,structure,'COL',ctx_reshaped)\n",
    "            uph = transform(enc,structure,'UPH',ctx_reshaped)\n",
    "            opt = transform(enc,structure,'OPT',ctx_reshaped,multilabel=True)\n",
    "            \n",
    "            pcts+=[self.cb.types_binarizer['CAR_TYPE'].transform([ct])[0]]\n",
    "            engs+=[self.cb.types_binarizer['ENGINE'].transform(eng)[0]]\n",
    "            svs+=[self.cb.types_binarizer['SALES_VERSION'].transform(sv)[0]]\n",
    "            gbs+=[self.cb.types_binarizer['GEARBOX'].transform(gb)[0]]\n",
    "            cols+=[self.cb.types_binarizer['COL'].transform(col)[0]]\n",
    "            uphs+=[self.cb.types_binarizer['UPH'].transform(uph)[0]]\n",
    "            opts+=[self.cb.types_binarizer['OPT'].transform(opt)[0]]\n",
    "\n",
    "        return [pcts,engs,svs,gbs,cols,uphs,opts]\n",
    "    \n",
    "    def evaluate(self, df):\n",
    "        self.stats = {\n",
    "            'CAR_TYPE':0,\n",
    "            'ENGINE':0,\n",
    "            'GEARBOX':0,\n",
    "            'SALES_VERSION':0,\n",
    "            'COL':0,\n",
    "            'UPH':0,\n",
    "            'OPT':0,\n",
    "            'TOTAL':0\n",
    "        }\n",
    "\n",
    "        predictions = self.predict(df[user_columns])\n",
    "        idx = 0\n",
    "        for ct,eng,sv,gb,col,uph,opts in tqdm_notebook(predictions):\n",
    "            row = df.iloc[idx]\n",
    "    \n",
    "            if ct in row['TYPECODE_translated']:\n",
    "                self.stats['CAR_TYPE'] += 1\n",
    "            if eng in row['ENGINECODE_translated']:\n",
    "                self.stats['ENGINE'] += 1\n",
    "            if gb in row['GEARBOXCODE_translated']:\n",
    "                self.stats['GEARBOX'] += 1\n",
    "            if sv in row['SALESVERSIONCODE_translated']:\n",
    "                self.stats['SALES_VERSION'] += 1\n",
    "            if col in row['COLOUR_translated']:\n",
    "                self.stats['COL'] += 1\n",
    "            if uph in row['UPHOLSTERY_translated']:\n",
    "                self.stats['UPH'] += 1\n",
    "\n",
    "            for o in row['OPT_CODES_translated']:\n",
    "                if o in opts:\n",
    "                    self.stats['OPT']+=1\n",
    "\n",
    "            idx += 1\n",
    "        self.stats['TOTAL'] = idx\n",
    "        return self.stats\n",
    "    \n",
    "        \n",
    "bnn = BNN(model_dict,train_ct[user_columns].shape[1],cb=cb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6c48c7f37d64198ae46c04f9b2fab5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c807eea813214ef28bb0a23440a62b95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=109274), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "for df in tqdm_notebook([train_ct ,train_sv,train_gb,train_eng,train_uph,train_col]):   \n",
    "    train = df\n",
    "    bnn.add_training_data(train[user_columns],train)\n",
    "    \n",
    "for df in tqdm_notebook([dev]):   \n",
    "    devdata = df\n",
    "    bnn.add_validation_data(devdata[user_columns],devdata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ksm.fit(verbose=2,epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evaluator = Evaluator(test,1,sample_size=10) #10 for now, just to show it\n",
    "evaluator.enqueue(Pno34ModelResolver(ksm,cb,pno12_solver,pnotype=PNO12,use_solver=False), 'ksm_no_solver_pno12')\n",
    "evaluator.enqueue(Pno34ModelResolver(ksm,cb,pno12_solver,pnotype=PNO34,use_solver=False), 'ksm_no_solver_pno34')\n",
    "evaluator.enqueue(Pno34ModelResolver(ksm,cb,pno12_solver,pnotype=CIS,use_solver=False), 'ksm_no_solver_cis')\n",
    "\n",
    "\n",
    "for t in np.arange(0.2,1.1,0.2):\n",
    "    evaluator.enqueue(Pno34ModelResolver(ksm,cb,pno12_solver,threshold=t,pnotype=CIS,use_solver=True), f'ksm_w.solver_thres:{t}_CIS')\n",
    "\n",
    "evaluator.enqueue(Pno34ModelResolver(ksm,cb,pno12_solver,pnotype=PNO12,use_solver=True), 'ksm_w.solver_pno12')\n",
    "evaluator.enqueue(Pno34ModelResolver(ksm,cb,pno12_solver,pnotype=PNO34,use_solver=True), 'ksm_w.solver_pno34')\n",
    "evaluator.enqueue(Pno34ModelResolver(ksm,cb,pno12_solver,pnotype=CIS,use_solver=True), 'ksm_w.solver_cis')\n",
    "\n",
    "\n",
    "evaluator.run_queue()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
