{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First, \n",
    "we declare some helper functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Component mappings\n",
    "We map from solver component (a component described using year, ct, en, sv, gb and component code) to a general component (described using component type and component code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphlib.types import Types\n",
    "import numpy as np\n",
    "\n",
    "def solver_comps_to_comps(solver_cmps):\n",
    "    \n",
    "    cmps = []\n",
    "    for scmp in solver_cmps:\n",
    "        try:\n",
    "            _,t,c = scmp.split('__')\n",
    "        except:\n",
    "            raise Exception(\"lol\")\n",
    "        if t == Types.PNO12:\n",
    "            ct,en,sv,gb = c.split(\"_\")\n",
    "            cmps.append((ct, Types.CAR_TYPE, ct))\n",
    "            cmps.append((ct, Types.ENGINE, en))\n",
    "            cmps.append((ct, Types.SALES_VERSION, sv))\n",
    "            cmps.append((ct, Types.GEARBOX, gb))\n",
    "        else:\n",
    "            _,ct,_,_,_,code = c[:4], c[4:7], c[7:9], c[9:11], c[11:12], c[12:]\n",
    "            cmps.append((ct,t,code))\n",
    "            \n",
    "    return cmps\n",
    "\n",
    "def solver_comps_to_vector(solver_cmps):\n",
    "    w = 0\n",
    "    for cmp in solver_comps_to_comps(solver_cmps):\n",
    "        w += weights[comp_space['comp_idx'][cmp]]\n",
    "        \n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solver\n",
    "The solver function takes a weight vector $w$, a weight matrix $ws$ (containing a weight per component), the car type $ct$, the rules set (A_ubs,...,b_eqs) and a mapping from component index $i$ to a component tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gurobipy import *\n",
    "from tqdm import tqdm_notebook\n",
    "import cvxpy as cp\n",
    "\n",
    "def is_satisfied(c, A_ub, b_ub, A_eq, b_eq):\n",
    "        \n",
    "    ub_TT = np.dot(A_ub,c).T <= b_ub\n",
    "    eq_TT = np.dot(A_eq,c).T == b_eq\n",
    "\n",
    "    f_TT = np.all(ub_TT) and np.all(eq_TT)\n",
    "\n",
    "    return f_TT\n",
    "\n",
    "def get_solver_data(ct, css):\n",
    "    return css[ct].i2c, css[ct].A_ubs, css[ct].b_ubs, css[ct].A_eqs, css[ct].b_eqs\n",
    "    \n",
    "def solve(w, ws, ct, A_ubs, b_ubs, A_eqs, b_eqs, i2c):\n",
    "    \n",
    "    n = len(i2c)\n",
    "    \n",
    "    # Define and solve the CVXPY problem.\n",
    "    x = cp.Variable(n, boolean=True)\n",
    "    prob = cp.Problem(cp.Minimize(cp.norm(ws[ct].T@x - w)), [\n",
    "        A_ubs@x <= b_ubs, \n",
    "        A_eqs@x == b_eqs\n",
    "        ])\n",
    "    prob.solve(solver=cp.GUROBI)\n",
    "\n",
    "    try:\n",
    "        items = i2c[np.argwhere(x.value == 1).T[0].tolist()]\n",
    "        res = (prob.status, items, x.value, prob.value)\n",
    "    except:\n",
    "        res = (prob.status, None, None, None)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The $css$\n",
    "contains the rules set and all components on solver component level. The css is general for all algorithms. The css is indexed using car types and then contains the component to index, and vice versa, mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphlib.component_graph import ComponentGraph\n",
    "from graphlib.component_solver import ComponentSolver\n",
    "\n",
    "cts = [\"225\",\"236\",\"536\",\"525\",\"246\",\"256\",\"235\",\"234\",\"227\",\"526\",\"224\"]\n",
    "cg = ComponentGraph(\"bolt://localhost:7687\", \"neo4j\", \"\")\n",
    "\n",
    "css = {ct:ComponentSolver(cg.setup_rule_system(ct)) for ct in cts}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mappings\n",
    "We need to define some mappings. First, we need to construct a dict of all the components on a general level, then give an index to each one of those (c2i, i2c). We also will need a mapping from solver components to general components (cs2cf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphlib.MDict import MDict\n",
    "\n",
    "cmps = set()\n",
    "cs2cf = {}\n",
    "for ct in css.keys():\n",
    "    for cmp in css[ct].c2i.keys():\n",
    "        _,t,c = cmp.split('__')\n",
    "        if t == Types.PNO12:\n",
    "            ct,en,sv,gb = c.split('_')\n",
    "            n_cmps = [(Types.CAR_TYPE, ct), (Types.ENGINE, en), (Types.SALES_VERSION, sv), (Types.GEARBOX, gb)]\n",
    "            cmps.update(set(n_cmps))\n",
    "            cs2cf[cmp] = n_cmps\n",
    "        else:\n",
    "            code = c[12:]\n",
    "            n_c = (t,code)\n",
    "            cmps.add(n_c)\n",
    "            cs2cf[cmp] = n_c\n",
    "\n",
    "cmps_list = list(cmps)\n",
    "\n",
    "i2c = {i:cmps_list[i] for i in range(len(cmps_list))}\n",
    "c2i = {c:i for i,c in i2c.items()}\n",
    "\n",
    "i2c = MDict(i2c)\n",
    "c2i = MDict(c2i)\n",
    "cs2cf = MDict(cs2cf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All current car types\n",
    "cts = [\"225\",\"236\",\"536\",\"525\",\"246\",\"256\",\"235\",\"234\",\"227\",\"526\",\"224\"]\n",
    "\n",
    "# ct to idx mappings\n",
    "ct2i = {cts[i]:i for i in range(len(cts))}\n",
    "i2ct = {i:ct for ct,i in ct2i.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The test function\n",
    "The algorithm is taking a list of contexts and cars, where the map_car2idxs function maps a car to its general indices, a weight matrix, the ct model predicting a car type and a point model predicting a point in the component space (cmp2vec or distributional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(ctxs_test, cars_test, ws, ct_model, p_model, map_car2vec=None, n_samples=None, ct_vecs=None):\n",
    "    \n",
    "    if map_car2vec == None:\n",
    "        raise Exception(\"'map_car2idxs' must be supplied\")\n",
    "\n",
    "    not_satisfied = []\n",
    "    ct_pred_dist = {}\n",
    "    y_s, y_preds = [],[]\n",
    "    \n",
    "    pairs = list(zip(ctxs_test, cars_test))\n",
    "    n_samples = n_samples if not n_samples == None else len(pairs)\n",
    "    current_pairs = pairs[:n_samples]\n",
    "    np.random.shuffle(current_pairs)\n",
    "    \n",
    "    for i in tqdm_notebook(range(len(current_pairs))):\n",
    "        ctx, car = current_pairs[i]\n",
    "        y = map_car2vec(car)\n",
    "        \n",
    "        if ct_vecs == None:\n",
    "            ct = np.random.choice(cts, p=ct_model.predict(ctx.reshape(1,-1))[0])\n",
    "            ct_pred = np.zeros((len(ct2i)))\n",
    "            ct_pred[ct2i[ct]] = 1\n",
    "            p_pred = p_model.predict([[ct_pred], [ctx]]).T[0]\n",
    "        else:\n",
    "            ct, p_pred = ct_vecs[i]\n",
    "\n",
    "        i2c_, A_ubs, b_ubs, A_eqs, b_eqs = get_solver_data(ct, css)\n",
    "        p, scmps, x, d = solve(p_pred, ws, ct, A_ubs, b_ubs, A_eqs, b_eqs, i2c_)\n",
    "\n",
    "        is_sat = is_satisfied(x, A_ubs, b_ubs, A_eqs, b_eqs)\n",
    "        if not is_sat:\n",
    "            print(\"Item {} was not satisfied\".format(i))\n",
    "            not_satisfied.append((i, is_sat))\n",
    "            continue\n",
    "\n",
    "        y_pred = np.zeros((len(i2c)))\n",
    "        for cs in scmps:\n",
    "            cf = cs2cf[cs]\n",
    "            idx = c2i[cf]\n",
    "            y_pred[idx] = 1\n",
    "\n",
    "        y_s.append(y)\n",
    "        y_preds.append(y_pred)\n",
    "        \n",
    "    loss = np.mean(np.square(np.array(y_s), np.array(y_preds)))\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm 1b\n",
    "Here we will make use of the item2vec (1d) weights and solver to find a decent car to a user context. First, the algorithm predicts a car type $ct$ and then a vector $v$ in the car space. The solver then takes $v$ and $ct$ as input and finds the nearest car. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we get the component space along with the translated cars and ctx pairs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 1: compenent2vec\n",
    "First, we load the components generated from the component2vec method along with the weights for each component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "dims = 1\n",
    "\n",
    "X_train, X_test, y_train_cmps, y_test_cmps = pickle.load(open(\"data/training_test_data/item2vec_dataset.pkl\", \"rb\"))\n",
    "comp_space = pickle.load(open(\"data/component_space_{}d_no_packages.pickle\".format(dims), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}\n",
    "for cmps in y_train_cmps:\n",
    "    _,_,cmp = cmps[0].split('__')\n",
    "    ct = cmp[:3]\n",
    "    if not ct in d:\n",
    "        d[ct] = 0\n",
    "        \n",
    "    d[ct] += 1\n",
    "    \n",
    "e = {}\n",
    "for cmps in y_train_cmps:\n",
    "    u_cmps = tuple(cmps)\n",
    "    if not u_cmps in e:\n",
    "        e[u_cmps] = 0\n",
    "    \n",
    "    e[u_cmps] += 1\n",
    "    \n",
    "len(e.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_opts = []\n",
    "for cmps in y_test_cmps:\n",
    "    count = 0\n",
    "    for c in cmps:\n",
    "        _,t,_ = c.split(\"__\")\n",
    "        if t == Types.OPT:\n",
    "            count += 1\n",
    "        \n",
    "    n_opts.append(count)\n",
    "    \n",
    "print(np.mean(n_opts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a weight matrix for solver components \n",
    "Here we create the weight matrix from the component space (generated from component2vec) such that it maps to each solver component in the $css$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws_cmp2vec = {}\n",
    "for ct in cts:\n",
    "    if not ct in ws_cmp2vec:\n",
    "        ws_cmp2vec[ct] = []\n",
    "        \n",
    "    for c in css[ct].i2c.values():\n",
    "        _, t, cm = c.split('__')\n",
    "        cms = cm.split('_')\n",
    "        z = 0\n",
    "        if len(cms) > 1:\n",
    "            ct, en, sv, gb = cms\n",
    "            for m in [(ct, Types.CAR_TYPE, ct), (ct, Types.ENGINE, en), (ct, Types.SALES_VERSION, sv), (ct, Types.GEARBOX, gb)]:\n",
    "                z += weights[comp_space['comp_idx'][m]]\n",
    "        else:\n",
    "            _, ct, _, _, _, ocu = cms[0][:4], cms[0][4:7], cms[0][7:9], cms[0][9:11], cms[0][11:12], cms[0][12:]            \n",
    "            z += weights[comp_space['comp_idx'][(ct, t, ocu)]]\n",
    "            \n",
    "        ws_cmp2vec[ct].append(z)\n",
    "        \n",
    "for ct in cts:\n",
    "    ws_cmp2vec[ct] = np.array(ws_cmp2vec[ct])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_space.keys(), X_train.shape, len(y_train_cmps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define some key variables. Move weight space to positive side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.abs(np.min(comp_space['weights'])) + comp_space['weights']\n",
    "np.min(weights), np.min(comp_space['weights'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build train-test dataset for ct model\n",
    "Here, we do not find the average car type within each context but rather compute for every car type in the context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ct_train= []\n",
    "for cmps in y_train_cmps:\n",
    "    try:\n",
    "        ct = cmps[0][9:12]\n",
    "\n",
    "        ct_idx = ct2i[ct]\n",
    "        z = np.zeros((len(ct2i)))\n",
    "        z[ct_idx] = 1\n",
    "        y_ct_train.append(z)\n",
    "    except:\n",
    "        print(cmps)\n",
    "        \n",
    "y_ct_train = np.array(y_ct_train)\n",
    "\n",
    "y_ct_test = []\n",
    "for cmps in y_test_cmps:\n",
    "    ct = cmps[0][9:12]\n",
    "    \n",
    "    ct_idx = ct2i[ct]\n",
    "    z = np.zeros((len(ct2i)))\n",
    "    z[ct_idx] = 1\n",
    "    y_ct_test.append(z)\n",
    "y_ct_test = np.array(y_ct_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0], y_ct_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create car type model\n",
    "This will take a context as input and predict one car type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "\n",
    "def euclidean_distance_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Euclidean distance loss\n",
    "    https://en.wikipedia.org/wiki/Euclidean_distance\n",
    "    :param y_true: TensorFlow/Theano tensor\n",
    "    :param y_pred: TensorFlow/Theano tensor of the same shape as y_true\n",
    "    :return: float\n",
    "    \"\"\"\n",
    "    return K.sqrt(K.sum(K.square(y_pred - y_true), axis=-1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model as KModel\n",
    "from keras.layers import Dense, Input, concatenate\n",
    "from keras.callbacks import TensorBoard,ReduceLROnPlateau,EarlyStopping\n",
    "from keras.optimizers import Adam, sgd\n",
    "\n",
    "def get_car_type_model(input_size, output_size):\n",
    "    input_r = Input(shape=(input_size,))\n",
    "    \n",
    "    dense_hidden_layer = Dense(1000, activation='relu')(input_r)\n",
    "    dense_hidden_layer = Dense(1000, activation='relu')(dense_hidden_layer)\n",
    "    output_layer = Dense(output_size, activation='softmax')(dense_hidden_layer)\n",
    "    \n",
    "    model = KModel(inputs=[input_r], outputs=output_layer)\n",
    "    model.name = \"CAR_TYPE_MODEL\"\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=sgd(lr=0.00001), metrics=['accuracy'])\n",
    "    \n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile car type model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_model = get_car_type_model(X_train.shape[1], y_ct_train.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit car type model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ct_model.fit(X_train, y_ct_train, validation_data=(X_test, y_ct_test), epochs=1000, callbacks=[\n",
    "    EarlyStopping(monitor=\"loss\", patience=5),\n",
    "    ReduceLROnPlateau(monitor='loss',verbose=1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create point model training sets\n",
    "We need to map each component in the training sets to a point in the component space. Since it is created using the l2-norm, we use the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_p_train = []\n",
    "for cmps in y_train_cmps:\n",
    "        \n",
    "    z = []\n",
    "    for ct,t,c in solver_comps_to_comps(cmps):\n",
    "        z.append(weights[comp_space['comp_idx'][(ct,t,c)]])\n",
    "\n",
    "    z_norm = np.linalg.norm(z)\n",
    "    y_p_train.append(z_norm)\n",
    "    \n",
    "y_p_test = []\n",
    "for i in range(len(y_test_cmps)):\n",
    "    cmps = y_test_cmps[i]\n",
    "\n",
    "    z = []\n",
    "    for ct,t,c in solver_comps_to_comps(cmps):\n",
    "        z.append(weights[comp_space['comp_idx'][(ct,t,c)]])\n",
    "\n",
    "    z_norm = np.linalg.norm(z)\n",
    "    y_p_test.append(z_norm)\n",
    "    \n",
    "y_p_train = np.array(y_p_train)\n",
    "y_p_test = np.array(y_p_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(y_p_train), np.var(y_p_train), np.max(y_p_train), np.min(y_p_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seaborn import kdeplot\n",
    "\n",
    "kdeplot(y_p_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the ct train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ct_train = []\n",
    "X_ct_test = []\n",
    "\n",
    "for cmps in y_train_cmps:\n",
    "    _,t,c = cmps[0].split(\"__\")\n",
    "    \n",
    "    if not t == Types.PNO12:\n",
    "        raise Exception(\"no, no\")\n",
    "            \n",
    "    ct = c[:3]\n",
    "    z = np.zeros((len(ct2i)))\n",
    "    idx = ct2i[ct]\n",
    "    z[idx] = 1\n",
    "    X_ct_train.append(z)\n",
    "    \n",
    "for cmps in y_test_cmps:\n",
    "    _,t,c = cmps[0].split(\"__\")\n",
    "    \n",
    "    if not t == Types.PNO12:\n",
    "        raise Exception(\"no, no\")\n",
    "            \n",
    "    ct = c[:3]\n",
    "    z = np.zeros((len(ct2i)))\n",
    "    idx = ct2i[ct]\n",
    "    z[idx] = 1\n",
    "    X_ct_test.append(z)\n",
    "\n",
    "X_ct_train = np.array(X_ct_train)\n",
    "X_ct_test = np.array(X_ct_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import concatenate\n",
    "\n",
    "def get_point_model(ct_input_size, ctx_input_size, output_size, loss='mse'):\n",
    "    input_l = Input(shape=(ct_input_size,))\n",
    "    input_r = Input(shape=(ctx_input_size,))\n",
    "    \n",
    "    dense_hidden_layer_l = Dense(1000, activation='relu')(input_l)\n",
    "    dense_hidden_layer_r = Dense(1000, activation='relu')(input_r)\n",
    "    \n",
    "    concat_layer = concatenate([dense_hidden_layer_l, dense_hidden_layer_r])\n",
    "    \n",
    "    dense_hidden_layer = Dense(1000, activation='relu')(concat_layer)\n",
    "    output_layer = Dense(output_size, activation='relu')(dense_hidden_layer)\n",
    "    \n",
    "    model = KModel(inputs=[input_l,input_r], outputs=output_layer)\n",
    "    model.name = \"POINT_MODEL\"\n",
    "    model.compile(loss=loss, optimizer=sgd(lr=0.00001))\n",
    "    \n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_model = get_point_model(y_ct_train.shape[1], X_train.shape[1], 1, loss=euclidean_distance_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "p_history = point_model.fit([X_ct_train, X_train], y_p_train, validation_data=([X_ct_test, X_test], y_p_test), epochs=1000000, callbacks=[\n",
    "    EarlyStopping(monitor=\"loss\", patience=5),\n",
    "    ReduceLROnPlateau(monitor='loss',verbose=1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate car vectors from test set\n",
    "First, we take the test set $y$ containing weights and regenerate cars using the solver. We then compare the generated component vectors with the correct in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def car2idxs_cmpvec(car):\n",
    "    z = np.zeros((len(c2i)))\n",
    "    c_cmps = cs2cf[car]\n",
    "    idxs = c2i[c_cmps[0]]\n",
    "    z[idxs] = 1\n",
    "    \n",
    "    return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algorithm 1. MSE <b>after solver</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a risk that the solver doesn't successfully find a satisfied components vector. In that case, we just discard those examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_ys, z_yps = test(X_test, y_test_cmps, ws_cmp2vec, ct_model, point_model, map_car2vec=car2idxs_cmpvec, n_samples=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.square(z_ys - z_yps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Random Car Picker\n",
    "The algorithm works as follows. First, we calculate the distribution $D$ of number of components as a truncated normal distribution. Then, for every new car, we randomly pick an integer $k$ from $D$ and then chooses $k$ optional components randomly. For each mandatory component, we randomly pick one of each with equal probability (or pick one PNO34). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, calculate distribution for optional components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nD = []\n",
    "for cmps in y_train_cmps:\n",
    "    opts = []\n",
    "    for cmp in cmps:\n",
    "        _,t,c = cmp.split('__')\n",
    "        if t == Types.OPT: \n",
    "            opts.append((t,c))\n",
    "            \n",
    "    n = len(opts)\n",
    "    nD.append(n)\n",
    "nD = np.array(nD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l, h, mu, sd = np.min(nD), np.max(nD), np.mean(nD), np.var(nD)\n",
    "l, h, mu, sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import truncnorm\n",
    "\n",
    "opt_dist = truncnorm((l - mu) / sd, (h - mu) / sd, loc=mu, scale=sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_opts = int(round(opt_dist.rvs()))\n",
    "n_opts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, calculate how many items for each mandatory component type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cts = list(css.keys())\n",
    "pno12s = MDict({})\n",
    "ct_cpms = MDict({})\n",
    "for ct in css.keys():\n",
    "    ct_cpms[ct] = MDict({})\n",
    "    pno12s[ct] = []\n",
    "    for i in css[ct].i2c.keys():\n",
    "        c_full = css[ct].i2c[i]\n",
    "        _,t,c = c_full.split('__')\n",
    "        if t == Types.PNO12:\n",
    "            pno12s[ct].append(c_full)\n",
    "        else:\n",
    "            if not t in ct_cpms[ct]:\n",
    "                ct_cpms[ct][t] = []\n",
    "                \n",
    "            ct_cpms[ct][t].append(c_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_cpms['227'][Types.COL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.choice(ct_cpms['225'][Types.COL])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test random algorithm\n",
    "Now we are ready to test. We create a test set of size $|z_{ys}|$ and then compute mean squared error with $z_{ys}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_ryps = []\n",
    "z_ryps_ss = []\n",
    "m_types = [Types.COL, Types.UPH]\n",
    "\n",
    "for i in range(z_ys.shape[0]):\n",
    "    z_p_cmps = []\n",
    "    \n",
    "    ct = np.random.choice(cts)\n",
    "    pno12 = np.random.choice(pno12s[ct])\n",
    "    col = np.random.choice(ct_cpms[ct][Types.COL])\n",
    "    uph = np.random.choice(ct_cpms[ct][Types.UPH])\n",
    "    \n",
    "    k = int(round(opt_dist.rvs()))\n",
    "    opts = np.random.choice(ct_cpms[ct][Types.OPT], k)\n",
    "    \n",
    "    z_p_cmps.append(pno12)\n",
    "    z_p_cmps.append(col)\n",
    "    z_p_cmps.append(uph)\n",
    "    z_p_cmps += opts.tolist()\n",
    "    z_s = np.zeros((len(css[ct].i2c)))\n",
    "    z_s[css[ct].c2i[z_p_cmps]] = 1\n",
    "        \n",
    "    w = np.sum(ws[ct][np.argwhere(z_s == 1)])\n",
    "    \n",
    "    z_ryps_ss.append((ct, w))\n",
    "    z_ryps.append(z_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_ryps = np.array(z_ryps)\n",
    "z_ryps.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test result <b>without solver</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean((z_ys - z_ryps)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test RCP with solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 100\n",
    "y_preds = []\n",
    "not_satisfied = []\n",
    "for i in tqdm_notebook(range(len(z_ryps_ss[:sample_size]))):\n",
    "    ct, w = z_ryps_ss[i]\n",
    "    n, ct_i2c, A_ubs, b_ubs, A_eqs, b_eqs = get_solve_data(ct, css)\n",
    "    p, scmps, x, d = solve(n, w, ws, ct, A_ubs, b_ubs, A_eqs, b_eqs, ct_i2c)\n",
    "    \n",
    "    is_sat = is_satisfied(x, A_ubs, b_ubs, A_eqs, b_eqs)\n",
    "    if not is_sat:\n",
    "        print(\"Item {} was not satisfied\".format(i))\n",
    "    \n",
    "    not_satisfied.append((i, is_sat))\n",
    "    \n",
    "    cmps = [(x[1], x[2]) for x in solver_comps_to_comps(scmps)]\n",
    "    y_pred = np.zeros((len(i2c)))\n",
    "    y_pred[c2i[cmps]] = 1\n",
    "    \n",
    "    y_preds.append(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ns = [x[1] for x in not_satisfied]\n",
    "np.mean(((z_ys[:sample_size].T*ns).T - (np.array(y_preds).T*ns).T)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 2: component distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "df_train = pickle.load(open(\"data/training_test_data/train.pickle\", 'rb'))\n",
    "df_test = pickle.load(open(\"data/training_test_data/test.pickle\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['TYPECODE', 'ENGINECODE', 'SALESVERSIONCODE', 'COLOUR', 'UPHOLSTERY',\n",
    "       'GEARBOXCODE', 'OPT_CODES','MODEL_YEAR', 'ENGINECODE_dist',\n",
    "       'TYPECODE_dist', 'SALESVERSIONCODE_dist', 'GEARBOXCODE_dist',\n",
    "       'COLOUR_dist', 'UPHOLSTERY_dist', 'OPT_CODES_dist', 'WORKING_PNO34',\n",
    "       'ENGINECODE_translated', 'TYPECODE_translated',\n",
    "       'SALESVERSIONCODE_translated', 'GEARBOXCODE_translated',\n",
    "       'COLOUR_translated', 'UPHOLSTERY_translated', 'OPT_CODES_translated']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2d = {}\n",
    "m_types = [Types.ENGINE, Types.SALES_VERSION, Types.GEARBOX, Types.COL, Types.UPH]\n",
    "for r in df_train[columns].values:\n",
    "    #my = r[7]\n",
    "    ct, ct_d = r[17], r[9]\n",
    "    c2d[(ct,Types.CAR_TYPE,ct)] = ct_d\n",
    "\n",
    "    for (t,c),d in zip(list(zip(m_types, r[[16,18,19,20,21]])), r[[8,10,11,12,13]]):\n",
    "        cmp = (ct,t,c)\n",
    "        if not cmp in c2d:\n",
    "            c2d[cmp] = []\n",
    "        \n",
    "        c2d[cmp].append(d)\n",
    "    \n",
    "    for c,d in zip(r[6], r[14]):\n",
    "        cmp = (ct, Types.OPT, c)\n",
    "        if not cmp in c2d:\n",
    "            c2d[cmp] = []\n",
    "\n",
    "        c2d[cmp].append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = {}\n",
    "for cmps in df_train[['ENGINECODE_translated', 'TYPECODE_translated',\n",
    "       'SALESVERSIONCODE_translated', 'GEARBOXCODE_translated',\n",
    "       'COLOUR_translated', 'UPHOLSTERY_translated', 'OPT_CODES_translated']].values:\n",
    "    u_cmps = tuple(cmps[:-1].tolist() + list(cmps[-1]))\n",
    "    if not u_cmps in e:\n",
    "        e[u_cmps] = 0\n",
    "    \n",
    "    e[u_cmps] += 1\n",
    "    \n",
    "len(e.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, ds in c2d.items():\n",
    "    c2d[k] = np.mean(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_columns = [\n",
    "     'antal_inpendlare',\n",
    "     'antal_utpendlare',\n",
    "     'förvärvs-arbetande',\n",
    "     'ej_förvärvs-arbetande',\n",
    "     'äganderätt/småhus',\n",
    "     'bostadsrätt',\n",
    "     'hyresrätt',\n",
    "     'övriga_inkl._uppgift_saknas',\n",
    "     'förgymnasial',\n",
    "     'gymnasial',\n",
    "     'eftergymnasial_mindre_än_3_år',\n",
    "     'eftergymnasial_3_år_eller_längre_inkl._forskarutbildning',\n",
    "     '0-6_år',\n",
    "     '7-15_år',\n",
    "     '16-19_år',\n",
    "     '20-24_år',\n",
    "     '25-44_år',\n",
    "     '45-64_år',\n",
    "     '65-w_år',\n",
    "     'låg_inkomst',\n",
    "     'medellåg_inkomst',\n",
    "     'medelhög_inkomst',\n",
    "     'hög_inkomst',\n",
    "     'medianinkomst',\n",
    "     'sammanboende_med_barn',\n",
    "     'sammanboende_utan_barn',\n",
    "     'ensamstående_med_barn',\n",
    "     'ensamstående_utan_barn',\n",
    "     'övriga_hushåll',\n",
    "     'låg_köpkraft',\n",
    "     'medellåg_köpkraft',\n",
    "     'medelhög_köpkraft',\n",
    "     'hög_köpkraft',\n",
    "     'median_köpkraft',\n",
    "     'jordbruk,_skogsbruk,_jakt_och_fiske',\n",
    "     'tillverkning_och_utvinning',\n",
    "     'energi_och_miljöverksamhet',\n",
    "     'byggverksamhet',\n",
    "     'handel',\n",
    "     'transport_och_magasinering',\n",
    "     'hotell-_och_restaurangverksamhet',\n",
    "     'information_och_kommunikation',\n",
    "     'finans-_och_försäkringsverksamhet',\n",
    "     'fastighetsverksamhet',\n",
    "     'företagstjänster',\n",
    "     'offentlig_förvaltning_och_försvar',\n",
    "     'utbildning',\n",
    "     'vård_och_omsorg,_sociala_tjänster',\n",
    "     'kulturella_och_personliga_tjänster_m.m.',\n",
    "     'okänd_verksamhet',\n",
    "     '0_barn',\n",
    "     '1_barn',\n",
    "     '2_barn',\n",
    "     '3+_barn'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctxs_train = df_train[context_columns].values\n",
    "cars_train = df_train[['TYPECODE_translated', 'ENGINECODE_translated', 'SALESVERSIONCODE_translated', 'GEARBOXCODE_translated','COLOUR_translated', 'UPHOLSTERY_translated', 'OPT_CODES_translated']].values\n",
    "\n",
    "ctxs_test = df_test[context_columns].values\n",
    "cars_test = df_test[['TYPECODE_translated', 'ENGINECODE_translated', 'SALESVERSIONCODE_translated', 'GEARBOXCODE_translated','COLOUR_translated', 'UPHOLSTERY_translated', 'OPT_CODES_translated']].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xy_ct_train here will be used in the first approximation function to train and predict a car type given the\n",
    "context. In the second approximation function we get the context <i>and</i> the car type as input and predict a point\n",
    "in the component distribution space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_datasets(ctxs, cars):\n",
    "    X_train, xy_ct_train, y_p_train = [],[],[]\n",
    "    for ctx,car in zip(ctxs, cars):\n",
    "        z = []\n",
    "        ct,en,sv,gb,col,uph,opts = car\n",
    "        z.append(c2d[(ct,Types.CAR_TYPE,ct)])\n",
    "\n",
    "        for t,c in zip(m_types, [en,sv,gb,col,uph]):\n",
    "            z.append(c2d[(ct,t,c)])\n",
    "\n",
    "        ct_z = np.zeros((len(ct2i)))\n",
    "        ct_idx = ct2i[ct]\n",
    "        ct_z[ct_idx] = 1\n",
    "\n",
    "        X_train.append(ctx)\n",
    "        xy_ct_train.append(ct_z)\n",
    "        \n",
    "        z_norm = np.linalg.norm(z)\n",
    "        y_p_train.append(z_norm)\n",
    "\n",
    "    return np.array(X_train), np.array(xy_ct_train), np.array(y_p_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, xy_ct_train, yd_p_train = build_datasets(ctxs_train, cars_train)\n",
    "X_train.shape, xy_ct_train.shape, y_p_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(yd_p_train), np.var(yd_p_train), np.min(yd_p_train), np.max(yd_p_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kdeplot(yd_p_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dct_model = get_car_type_model(X_train.shape[1], xy_ct_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dp_model = get_point_model(xy_ct_train.shape[1], X_train.shape[1], 1, loss=euclidean_distance_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dct_history = dct_model.fit(X_train, xy_ct_train, epochs=1000000, callbacks=[\n",
    "    EarlyStopping(monitor=\"loss\", patience=5),\n",
    "    ReduceLROnPlateau(monitor='loss',verbose=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dp_history = dp_model.fit([xy_ct_train, X_train], y_p_train, epochs=1000000, callbacks=[\n",
    "    EarlyStopping(monitor=\"loss\", patience=5),\n",
    "    ReduceLROnPlateau(monitor='loss',verbose=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(y_p_train), np.var(y_p_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build ws matrix\n",
    "Since we need weights to the solver in solver-component format, we iterate through all the components in the css and find the corresponding weight in the c2d dictionary. However, there might be components in css but not in c2d (the component has not been sold), then we just set the $d$ to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws_c2d = MDict()\n",
    "\n",
    "typs = [Types.CAR_TYPE, Types.ENGINE, Types.SALES_VERSION, Types.GEARBOX]\n",
    "for ct in css.keys():\n",
    "    ws_c2d[ct] = []\n",
    "    for cs in css[ct].c2i.keys():\n",
    "        _, t, cmps = cs.split('__')\n",
    "        if t == Types.PNO12:\n",
    "            w = []\n",
    "            ct,en,sv,gb = cmps.split('_')\n",
    "            for (t,c) in zip(typs, [ct,en,sv,gb]):\n",
    "                if not (ct,t,c) in c2d:\n",
    "                    w.append(0)\n",
    "                else:\n",
    "                    w.append(c2d[(ct,t,c)])\n",
    "                \n",
    "            w_norm = np.linalg.norm(w)\n",
    "            ws_c2d[ct].append(w_norm)\n",
    "        else:\n",
    "            \n",
    "            _,ct,_,_,_,c = cmps[:4], cmps[4:7], cmps[7:9], cmps[9:11], cmps[11:12], cmps[12:]\n",
    "            \n",
    "            if not (ct, t, c) in c2d:\n",
    "                w = 0\n",
    "            else:\n",
    "                w = c2d[(ct, t, c)]\n",
    "\n",
    "            ws_c2d[ct].append(w)\n",
    "            \n",
    "    ws_c2d[ct] = np.array(ws_c2d[ct])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws_c2d['225']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def car2idxs_dist(car):\n",
    "    z = np.zeros((len(c2i)))\n",
    "    idxs = c2i[list(zip([Types.CAR_TYPE, Types.ENGINE, Types.SALES_VERSION, Types.GEARBOX, Types.COL, Types.UPH], car[:-1]))]\n",
    "    idxs += c2i[[(Types.OPT, c) for c in car[-1]]]\n",
    "    z[idxs] = 1\n",
    "    \n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(ctxs_test, cars_test, ws_c2d, dct_model, dp_model, car2idxs_dist, n_samples=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dist(dataset, get_key = lambda k: k):\n",
    "    dist = {}\n",
    "    for c in dataset:\n",
    "        if not get_key(c) in dist:\n",
    "            dist[get_key(c)] = 0\n",
    "\n",
    "        dist[get_key(c)] += 1\n",
    "        \n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(get_dist(y_p_train)),len(get_dist(yd_p_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import pandas as pd\n",
    "ros = RandomOverSampler()\n",
    "\n",
    "types_df = ['TYPECODE']\n",
    "for key in types_df:\n",
    "    if 'OPT' in key:\n",
    "        continue\n",
    "    X_res, y_res = ros.fit_resample(df_train, df_train[f'{key}_translated'])\n",
    "    resampled = pd.DataFrame(X_res,columns=df_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled['TYPECODE_translated'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random using component distribution data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nD = []\n",
    "for cmps in cars_train:\n",
    "    n = len(cmps[6])\n",
    "    nD.append(n)\n",
    "nD = np.array(nD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l, h, mu, sd = np.min(nD), np.max(nD), np.mean(nD), np.var(nD)\n",
    "l, h, mu, sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_dist = truncnorm((l - mu) / sd, (h - mu) / sd, loc=mu, scale=sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_ryps = []\n",
    "z_ryps_ss = []\n",
    "w_vecs = []\n",
    "m_types = [Types.COL, Types.UPH]\n",
    "\n",
    "for i in range(len(y_test_cmps)):\n",
    "    z_p_cmps = []\n",
    "    \n",
    "    ct = np.random.choice(cts)\n",
    "    pno12 = np.random.choice(pno12s[ct])\n",
    "    col = np.random.choice(ct_cpms[ct][Types.COL])\n",
    "    uph = np.random.choice(ct_cpms[ct][Types.UPH])\n",
    "    \n",
    "    k = int(round(opt_dist.rvs()))\n",
    "    opts = np.random.choice(ct_cpms[ct][Types.OPT], k)\n",
    "    \n",
    "    z_p_cmps.append(pno12)\n",
    "    z_p_cmps.append(col)\n",
    "    z_p_cmps.append(uph)\n",
    "    z_p_cmps += opts.tolist()\n",
    "    \n",
    "    z_s = np.zeros((len(css[ct].i2c)))\n",
    "    z_s[css[ct].c2i[z_p_cmps]] = 1\n",
    "        \n",
    "    w = np.linalg.norm(ws_c2d[ct][np.argwhere(z_s == 1)])\n",
    "    w_vecs.append((ct,w))\n",
    "    #z_ryps_ss.append((ct, w))\n",
    "    z_ryps.append(z_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = list(zip(ctxs_test, cars_test))\n",
    "np.random.shuffle(pairs)\n",
    "ct_tst, cs_tst = zip(*pairs)\n",
    "\n",
    "test(ct_tst, cs_tst, ws_c2d, None, None, map_car2vec=car2idxs_dist, n_samples=10, ct_vecs=w_vecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss 0.024.. is a new result but not in paper. This is because of a results deadline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
